{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mitral Valve Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import jaccard_score\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from src.dataset import EchoDataset\n",
    "from src.model import UNet\n",
    "from src.train_utils import Trainer, WeightedCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\".\")\n",
    "\n",
    "PATH_TO_DATA = ROOT / \"data\"\n",
    "PATH_TO_TRAIN = PATH_TO_DATA / \"train.pkl\"\n",
    "PATH_TO_TEST = PATH_TO_DATA / \"test.pkl\"\n",
    "\n",
    "PATH_TO_OUTPUTS = ROOT / \"outputs\"\n",
    "PATH_TO_MODELS = PATH_TO_OUTPUTS / \"models\"\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(DEVICE)\n",
    "\n",
    "\n",
    "##################################################\n",
    "# Reproducibility\n",
    "##################################################\n",
    "SEED = 7\n",
    "random.seed(SEED)  # Used in some of the `torchvision` transformations.\n",
    "RS_NUMPY = np.random.default_rng(SEED)\n",
    "RS_TORCH = torch.manual_seed(SEED)\n",
    "\n",
    "\n",
    "# Warning: the settings commented below may slow down the execution time.\n",
    "\n",
    "# # PyTorch will only use deterministic operations.\n",
    "# # If no deterministic alternative exist, an error will be raised.\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "# # Reproducibility when using GPUs\n",
    "\n",
    "# # Choice of algorithms (in `cuDNN`) is deterministic.\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# # Algorithms themselves (only the ones in `cuDNN`) are deterministic.\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\"\"\"\n",
    "In some CUDA versions:\n",
    "- We need to set as well the `CUBLAS_WORKSPACE_CONFIG` environment variable.\n",
    "- RNN and LSTM networks may have non-deterministic behavior.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "##################################################\n",
    "# Hyperparameters\n",
    "##################################################\n",
    "N_EPOCHS = 80\n",
    "\n",
    "# Dataset\n",
    "IMG_SIZE = (320, 384)  # (W, H) Used by the resize transformation.\n",
    "N_CLASSES = 2  # Background (0), Mitral Valve (1).\n",
    "\n",
    "\n",
    "# Data Loader\n",
    "BATCH_SIZE = 25\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "\n",
    "# Model\n",
    "MODEL_PARAMS = {\n",
    "    \"in_channels\": 1,\n",
    "    \"out_channels\": N_CLASSES,\n",
    "    \"mid_channels\": [64, 128, 256, 512, 1024],\n",
    "    \"kernel_size\": 3,\n",
    "    \"max_pool_kernel_size\": 2,\n",
    "    \"up_kernel_size\": 2,\n",
    "    \"up_stride\": 2,\n",
    "    \"dropout_p\": 0.0,\n",
    "}\n",
    "model = UNet(**MODEL_PARAMS)\n",
    "\n",
    "\n",
    "# Loss Function\n",
    "# Weighting for classes to address imbalance.\n",
    "CLASS_WEIGHT = torch.tensor([1.0, 10.0], dtype=torch.float)\n",
    "# Weighting for data importance based on labeling source ('expert' vs. 'amateur' labeling).\n",
    "DATA_WEIGHT = torch.tensor([1.0, 3.0], dtype=torch.float)\n",
    "LOSS_PARAMS = {\"class_weight\": CLASS_WEIGHT, \"data_weight\": DATA_WEIGHT}\n",
    "LOSS_FN = WeightedCE(**LOSS_PARAMS)\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "OPTIMIZER_CLASS = Adam\n",
    "OPTIMIZER_PARAMS = {\"lr\": 0.01}\n",
    "optimizer = OPTIMIZER_CLASS(model.parameters(), **OPTIMIZER_PARAMS)\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "SCHEDULER_CLASS = StepLR\n",
    "SCHEDULER_PARAMS = {\"gamma\": 0.9, \"step_size\": 15}\n",
    "scheduler = SCHEDULER_CLASS(optimizer, **SCHEDULER_PARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Dataset Loading and Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    \"\"\"\n",
    "    Controlling randomness in multi-process data loading. The RNGs are used by the image transformations\n",
    "    and the RandomSampler, which generates random indices for data shuffling.\n",
    "    \"\"\"\n",
    "    # Use `torch.initial_seed` to access the PyTorch seed set for each worker.\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Data augmentation should create realistic variations likely to be encountered in clinical settings.\n",
    "This ensures the model's generalizability and effectiveness in real-world scenarios without training on implausible data.\n",
    "\"\"\"\n",
    "\n",
    "# Pixel values are in the range [0, 1]. To \"normalize\" them to the range [-1, 1], set `mean=0.5` and `std=0.5`.\n",
    "transforms = v2.Compose(\n",
    "    [\n",
    "        v2.RandomRotation(degrees=(-15, 15)),\n",
    "        v2.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2)),\n",
    "        v2.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.9, 1.1)),\n",
    "        v2.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = EchoDataset(PATH_TO_TRAIN, IMG_SIZE)\n",
    "# We were actually given a test dataset. However, this one didn't come with the labels.\n",
    "# Therefore, to assess the model's performance, we partition the training dataset in two.\n",
    "train_dataset, test_dataset = random_split(\n",
    "    dataset, lengths=[0.9, 0.1], generator=RS_TORCH\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=True,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=RS_TORCH,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=False,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=RS_TORCH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_echo(img, target=None, prediction=None):\n",
    "    \"\"\"Plots an echocardiogram with optional ground truth and prediction segmentations.\"\"\"\n",
    "    subplot_count = 1 if target is None else (3 if prediction is not None else 2)\n",
    "    plt.figure(figsize=(5 * subplot_count, 15))\n",
    "\n",
    "    img = img.permute(2, 1, 0).detach().cpu().numpy()\n",
    "\n",
    "    plt.subplot(1, subplot_count, 1)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.title(\"Echocardiogram\")\n",
    "\n",
    "    if target is not None:\n",
    "        target = target.permute(1, 0).detach().cpu().numpy()\n",
    "\n",
    "        plt.subplot(1, subplot_count, 2)\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "        plt.imshow(target, alpha=0.5, cmap=\"binary_r\")\n",
    "        plt.title(\"Ground Truth\")\n",
    "\n",
    "    if prediction is not None:\n",
    "        prediction = prediction.permute(1, 0).detach().cpu().numpy()\n",
    "\n",
    "        plt.subplot(1, subplot_count, 3)\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "        plt.imshow(prediction, alpha=0.5, cmap=\"binary_r\")\n",
    "        plt.title(\"Prediction\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "frame_idx = 0\n",
    "frame, segmentation, _ = dataset[frame_idx]\n",
    "plot_echo(frame, segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    train_loader,\n",
    "    model,\n",
    "    LOSS_FN,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    N_EPOCHS,\n",
    "    DEVICE,\n",
    "    PATH_TO_OUTPUTS,\n",
    ")\n",
    "\n",
    "# Start training process.\n",
    "trainer.train()\n",
    "\n",
    "# Save trainer state.\n",
    "trainer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Metrics Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_jaccard_score(prediction, target):\n",
    "    \"\"\"Calculate the mean Jaccard score.\"\"\"\n",
    "    if target.ndim > 2:\n",
    "        score = np.mean(\n",
    "            [\n",
    "                jaccard_score(target[i], prediction[i], average=\"micro\")\n",
    "                for i in range(target.shape[0])\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        score = jaccard_score(target, prediction, average=\"micro\")\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(eval_loader, model, eval_metric_fn, device):\n",
    "    \"\"\"Compute the evaluation metric for a model over a given DataLoader.\"\"\"\n",
    "    eval_mean = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, target, _ in eval_loader:\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            prediction = model.predict(inputs).detach().cpu()\n",
    "\n",
    "            eval_mean += eval_metric_fn(prediction, target).item()\n",
    "\n",
    "    return eval_mean / len(eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latest_model(path_to_models, model, device):\n",
    "    \"\"\"Load the most recently trained model from the outputs directory.\"\"\"\n",
    "    try:\n",
    "        latest_model_path = sorted(Path(path_to_models).iterdir())[-1]\n",
    "    except IndexError:\n",
    "        raise FileNotFoundError(\n",
    "            \"No model files found in the directory: {}\".format(path_to_models)\n",
    "        )\n",
    "\n",
    "    state = torch.load(latest_model_path, map_location=device)\n",
    "    model.load_state_dict(state[\"model_state_dict\"])\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "if \"trainer\" in globals() and hasattr(trainer, \"model\"):\n",
    "    model = trainer.model\n",
    "    print(\"Using recently trained model.\")\n",
    "else:\n",
    "    # If no model was trained (i.e., training process cell was not executed),\n",
    "    # load the most recently trained model.\n",
    "    model = load_latest_model(PATH_TO_MODELS, model, DEVICE)\n",
    "    print(\"Using last saved model.\")\n",
    "\n",
    "\n",
    "# Compute evaluation metric on the test dataset.\n",
    "eval_metric = evaluate(test_loader, model, mean_jaccard_score, DEVICE)\n",
    "print(f\"Jaccard Score: {eval_metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Result Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a prediction.\n",
    "model.eval()\n",
    "obs_idx = 0\n",
    "with torch.no_grad():\n",
    "    inputs, targets, _ = next(iter(test_loader))\n",
    "    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "    predictions = model.predict(inputs)\n",
    "\n",
    "    plot_echo(inputs[obs_idx], targets[obs_idx], predictions[obs_idx])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
